{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d1acdaa",
   "metadata": {},
   "source": [
    "# <font color=#6026B2>**Projet 7 : Impl√©menter un mod√®le de scoring**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa1279b",
   "metadata": {},
   "source": [
    "## Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5e34303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T17:02:07.125910Z",
     "start_time": "2024-09-19T17:02:04.636782Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "import re\n",
    "from contextlib import contextmanager\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "\n",
    "import mlflow\n",
    "#import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "#import warnings\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f94fed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T17:02:07.141869Z",
     "start_time": "2024-09-19T17:02:07.129901Z"
    }
   },
   "outputs": [],
   "source": [
    "# URL MLFlow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a0ecdc",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7136746",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a28ef6",
   "metadata": {},
   "source": [
    "### Data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c75867",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T17:02:12.258506Z",
     "start_time": "2024-09-19T17:02:07.143863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 307511, test samples: 48744\n"
     ]
    }
   ],
   "source": [
    "num_rows = None\n",
    "nan_as_category = False\n",
    "\n",
    "# Read data and merge\n",
    "train_df = pd.read_csv('Input_data/application_train.csv', nrows= num_rows)\n",
    "test_df = pd.read_csv('Input_data/application_test.csv', nrows= num_rows)\n",
    "print(\"Train samples: {}, test samples: {}\".format(len(train_df), len(test_df)))\n",
    "df = pd.concat([train_df, test_df]).reset_index(drop=True)\n",
    "# Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "df = df[df['CODE_GENDER'] != 'XNA']\n",
    "\n",
    "# Categorical features with Binary encode (0 or 1; two categories)\n",
    "for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "    df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "\n",
    "# Categorical features with One-Hot encode\n",
    "original_columns = list(df.columns)\n",
    "categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "\n",
    "# instancie objet OHE\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Utilise OHE\n",
    "df_new_cols = onehot_encoder.fit_transform(df[categorical_columns])\n",
    "\n",
    "# Cr√©ez un DataFrame avec les nouvelles colonnes encod√©es\n",
    "encoded_df = pd.DataFrame(df_new_cols, columns=onehot_encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# Supprimer les colonnes cat√©gorielles d'origine du DataFrame initial\n",
    "df = df.drop(categorical_columns, axis=1)\n",
    "\n",
    "# Concat√©nez le DataFrame d'origine avec le DataFrame contenant les nouvelles colonnes encod√©es\n",
    "df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "# NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "# Some simple new features (percentages)\n",
    "df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24e6da54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T17:02:12.290440Z",
     "start_time": "2024-09-19T17:02:12.261460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    253\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae64b3",
   "metadata": {},
   "source": [
    "## Modelisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c33d55",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8b4c8e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T17:02:18.214862Z",
     "start_time": "2024-09-19T17:02:12.295428Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307507, 253)\n",
      "(48748, 253)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:02:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/09/19 19:02:18 INFO mlflow.tracking._tracking_service.client: üèÉ View run thundering-wolf-787 at: http://127.0.0.1:8080/#/experiments/926137080585531510/runs/a03151ed88c74ca59dbdff8747299566.\n",
      "2024/09/19 19:02:18 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/926137080585531510.\n"
     ]
    }
   ],
   "source": [
    "# Initialiser exp√©rience MLflow\n",
    "mlflow.set_experiment(\"Baseline\")  # Nommer l'exp√©rience\n",
    "\n",
    "# Divide in training/validation and test data\n",
    "train_df = df[df['TARGET'].notnull()]\n",
    "test_df = df[df['TARGET'].isnull()]\n",
    "\n",
    "print (train_df.shape)\n",
    "print (test_df.shape)\n",
    "\n",
    "# S√©paration de la variable cible et des features\n",
    "y = train_df[\"TARGET\"]\n",
    "X = train_df.drop(\"TARGET\", axis=1)\n",
    "\n",
    "# Cr√©er et entra√Æner un mod√®le de baseline avec DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X, y)\n",
    "\n",
    "# Faire des pr√©dictions sur les donn√©es d'entra√Ænement\n",
    "y_pred = dummy_clf.predict(X)\n",
    "y_proba = dummy_clf.predict_proba(X)[:, 1]\n",
    "\n",
    "# Calculer les m√©triques\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "auc = roc_auc_score(y, y_proba)\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "\n",
    "# D√©marrer un nouveau run dans MLflow\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Enregistrer le mod√®le DummyClassifier\n",
    "    mlflow.sklearn.log_model(dummy_clf, \"dummy_classifier\")\n",
    "\n",
    "    # Enregistrer les m√©triques dans MLflow\n",
    "    mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"Recall\", recall)\n",
    "    mlflow.log_metric(\"Precision\", precision)\n",
    "    mlflow.log_metric(\"F1 Score\", f1)\n",
    "    mlflow.log_metric(\"AUC\", auc)\n",
    "\n",
    "    # Enregistrer la matrice de confusion comme artefact\n",
    "    with open(\"confusion_matrix.txt\", \"w\") as f:\n",
    "        f.write(str(conf_matrix))\n",
    "    mlflow.log_artifact(\"confusion_matrix.txt\")\n",
    "\n",
    "    # Enregistrer la strat√©gie utilis√©e pour DummyClassifier comme param√®tre\n",
    "    mlflow.log_param(\"strategy\", \"most_frequent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01be7ce",
   "metadata": {},
   "source": [
    "### LGBMclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5709ab6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T17:03:10.473448Z",
     "start_time": "2024-09-19T17:02:18.216859Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (261380, 252)\n",
      "Test shape: (48748, 253)\n",
      "Valid shape: (46127, 252)\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "[LightGBM] [Info] Number of positive: 16881, number of negative: 192223\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12975\n",
      "[LightGBM] [Info] Number of data points in the train set: 209104, number of used features: 241\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432467\n",
      "[LightGBM] [Info] Start training from score -2.432467\n",
      "[LightGBM] [Info] Number of positive: 16881, number of negative: 192223\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12978\n",
      "[LightGBM] [Info] Number of data points in the train set: 209104, number of used features: 242\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432467\n",
      "[LightGBM] [Info] Start training from score -2.432467\n",
      "[LightGBM] [Info] Number of positive: 16881, number of negative: 192223\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12977\n",
      "[LightGBM] [Info] Number of data points in the train set: 209104, number of used features: 242\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432467\n",
      "[LightGBM] [Info] Start training from score -2.432467\n",
      "[LightGBM] [Info] Number of positive: 16881, number of negative: 192223\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.134767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12972\n",
      "[LightGBM] [Info] Number of data points in the train set: 209104, number of used features: 242\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432467\n",
      "[LightGBM] [Info] Start training from score -2.432467\n",
      "[LightGBM] [Info] Number of positive: 16880, number of negative: 192224\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12975\n",
      "[LightGBM] [Info] Number of data points in the train set: 209104, number of used features: 242\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080725 -> initscore=-2.432532\n",
      "[LightGBM] [Info] Start training from score -2.432532\n",
      "AUROC moyen en validation crois√©e: 0.7615631629294765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/19 19:03:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'V0' already exists. Creating a new version of this model...\n",
      "2024/09/19 19:03:10 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: V0, version 6\n",
      "Created version '6' of model 'V0'.\n",
      "2024/09/19 19:03:10 INFO mlflow.tracking._tracking_service.client: üèÉ View run fortunate-bird-558 at: http://127.0.0.1:8080/#/experiments/900250469276927826/runs/9a7d691f0e674c78a75bf726ddce4640.\n",
      "2024/09/19 19:03:10 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/900250469276927826.\n"
     ]
    }
   ],
   "source": [
    "# Initialiser exp√©rience MLflow\n",
    "mlflow.set_experiment(\"LGBMClassifier\")  # Nommer l'exp√©rience\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, stratify=y, random_state=88)\n",
    "x_test = test_df\n",
    "print('Train shape:', x_train.shape)\n",
    "print('Test shape:', x_test.shape)\n",
    "print('Valid shape:', x_valid.shape)\n",
    "\n",
    "# remove caract√®res sp√©ciaux\n",
    "x_train = x_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "x_test = x_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "x_valid = x_valid.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "# On initialise le dictionnaire des hyperparam√®tres du mod√®le avec des valeurs arbitraires\n",
    "param_V0 = {\n",
    "        'n_estimators': 300,\n",
    "        'num_leaves': 15,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'subsample': 0.8,\n",
    "        'max_depth': 7,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 0.1,\n",
    "        'min_split_gain': 0.01\n",
    "        }\n",
    "\n",
    "# Initialisation du mod√®le\n",
    "clf = LGBMClassifier(**param_V0)\n",
    "\n",
    "#Entra√Ænement du mod√®le\n",
    "clf.fit(x_train,y_train, eval_metric='auc')\n",
    "\n",
    "# Pr√©dictions sur le jeu de validation\n",
    "y_pred = clf.predict(x_valid)\n",
    "y_proba = clf.predict_proba(x_valid)[:, 1]\n",
    "\n",
    "# Calculer les m√©triques sur le jeu de validation\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "recall = recall_score(y_valid, y_pred)\n",
    "precision = precision_score(y_valid, y_pred)\n",
    "f1 = f1_score(y_valid, y_pred)\n",
    "auc = roc_auc_score(y_valid, y_proba)\n",
    "conf_matrix = confusion_matrix(y_valid, y_pred)\n",
    "\n",
    "# Calculer l'AUROC avec validation crois√©e\n",
    "auroc_cv = cross_val_score(clf, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"AUROC moyen en validation crois√©e: {auroc_cv.mean()}\")\n",
    "\n",
    "# D√©marrer un nouveau run dans MLflow\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Enregistrer le mod√®le LGBMClassifier\n",
    "    mlflow.sklearn.log_model(clf, \"LGBMClassifier\", registered_model_name=\"V0\")\n",
    "\n",
    "    # Enregistrer les m√©triques dans MLflow\n",
    "    mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"Recall\", recall)\n",
    "    mlflow.log_metric(\"Precision\", precision)\n",
    "    mlflow.log_metric(\"F1 Score\", f1)\n",
    "    mlflow.log_metric(\"AUC\", auc)\n",
    "    mlflow.log_metric(\"AUROC_CV\", auroc_cv.mean())  # AUROC avec validation crois√©e\n",
    "\n",
    "    # Enregistrer la matrice de confusion comme artefact\n",
    "    with open(\"confusion_matrix.txt\", \"w\") as f:\n",
    "        f.write(str(conf_matrix))\n",
    "    mlflow.log_artifact(\"confusion_matrix.txt\")\n",
    "\n",
    "    # Enregistrer les hyperparam√®tres dans MLflow\n",
    "    mlflow.log_params(param_V0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02bdd763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T17:03:50.858771Z",
     "start_time": "2024-09-19T17:03:10.476416Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.172053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.27581\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16881, number of negative: 192223\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12975\n",
      "[LightGBM] [Info] Number of data points in the train set: 209104, number of used features: 241\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432467\n",
      "[LightGBM] [Info] Start training from score -2.432467\n",
      "[LightGBM] [Info] Number of positive: 16881, number of negative: 192223\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12978\n",
      "[LightGBM] [Info] Number of data points in the train set: 209104, number of used features: 242\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432467\n",
      "[LightGBM] [Info] Start training from score -2.432467\n",
      "[LightGBM] [Info] Number of positive: 16881, number of negative: 192223\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12977\n",
      "[LightGBM] [Info] Number of data points in the train set: 209104, number of used features: 242\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432467\n",
      "[LightGBM] [Info] Start training from score -2.432467\n",
      "[LightGBM] [Info] Number of positive: 16881, number of negative: 192223\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.180520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12972\n",
      "[LightGBM] [Info] Number of data points in the train set: 209104, number of used features: 242\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080730 -> initscore=-2.432467\n",
      "[LightGBM] [Info] Start training from score -2.432467\n",
      "[LightGBM] [Info] Number of positive: 16880, number of negative: 192224\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12975\n",
      "[LightGBM] [Info] Number of data points in the train set: 209104, number of used features: 242\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080725 -> initscore=-2.432532\n",
      "[LightGBM] [Info] Start training from score -2.432532\n",
      "AUROC moyen en validation crois√©e: 0.7615631629294765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/19 19:03:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'V0_CustomLoss'.\n",
      "2024/09/19 19:03:50 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: V0_CustomLoss, version 1\n",
      "Created version '1' of model 'V0_CustomLoss'.\n",
      "2024/09/19 19:03:50 INFO mlflow.tracking._tracking_service.client: üèÉ View run redolent-horse-507 at: http://127.0.0.1:8080/#/experiments/499045072515100634/runs/6b27cd0f637845f2a3f57d94f3305818.\n",
      "2024/09/19 19:03:50 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/499045072515100634.\n"
     ]
    }
   ],
   "source": [
    "# Initialiser exp√©rience MLflow\n",
    "mlflow.set_experiment(\"LGBMClassifier_CustomLoss\")  # Nommer l'exp√©rience\n",
    "\n",
    "# Fonction de perte personnalis√©e (pond√©rer FN 10 fois plus que FP)\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # Convertir les probabilit√©s en pr√©dictions binaires\n",
    "    y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "    # Calcul de la matrice de confusion\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary).ravel()\n",
    "\n",
    "    # Calcul du co√ªt pond√©r√©\n",
    "    cost = 10 * fn + fp  # Faux n√©gatif = 10 fois plus co√ªteux que faux positif\n",
    "    \n",
    "    # Retourner le co√ªt\n",
    "    return 'custom_cost', cost, False\n",
    "\n",
    "# Initialisation du mod√®le avec une fonction de perte personnalis√©e\n",
    "clf = LGBMClassifier(**param_V0)\n",
    "\n",
    "# Entra√Ænement du mod√®le en utilisant la fonction de perte personnalis√©e\n",
    "clf.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], eval_metric=custom_loss, callbacks=[early_stopping(stopping_rounds=10)]) \n",
    "\n",
    "# Pr√©dictions sur le jeu de validation\n",
    "y_pred = clf.predict(x_valid)\n",
    "y_proba = clf.predict_proba(x_valid)[:, 1]\n",
    "\n",
    "# Calculer les m√©triques sur le jeu de validation\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "recall = recall_score(y_valid, y_pred)\n",
    "precision = precision_score(y_valid, y_pred)\n",
    "f1 = f1_score(y_valid, y_pred)\n",
    "auc = roc_auc_score(y_valid, y_proba)\n",
    "conf_matrix = confusion_matrix(y_valid, y_pred)\n",
    "\n",
    "# Calculer l'AUROC avec validation crois√©e\n",
    "auroc_cv = cross_val_score(clf, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"AUROC moyen en validation crois√©e: {auroc_cv.mean()}\")\n",
    "\n",
    "# D√©marrer un nouveau run dans MLflow\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Enregistrer le mod√®le LGBMClassifier\n",
    "    mlflow.sklearn.log_model(clf, \"LGBMClassifier_CustomLoss\", registered_model_name=\"V0_CustomLoss\")\n",
    "\n",
    "    # Enregistrer les m√©triques dans MLflow\n",
    "    mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"Recall\", recall)\n",
    "    mlflow.log_metric(\"Precision\", precision)\n",
    "    mlflow.log_metric(\"F1 Score\", f1)\n",
    "    mlflow.log_metric(\"AUC\", auc)\n",
    "    mlflow.log_metric(\"AUROC_CV\", auroc_cv.mean())  # AUROC avec validation crois√©e\n",
    "\n",
    "    # Enregistrer la matrice de confusion comme artefact\n",
    "    with open(\"confusion_matrix.txt\", \"w\") as f:\n",
    "        f.write(str(conf_matrix))\n",
    "    mlflow.log_artifact(\"confusion_matrix.txt\")\n",
    "\n",
    "    # Enregistrer les hyperparam√®tres dans MLflow\n",
    "    mlflow.log_params(param_V0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926a7b20",
   "metadata": {},
   "source": [
    "### Optimisation bay√©sienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "827be146",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T17:10:39.534093Z",
     "start_time": "2024-09-19T17:08:25.388843Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | max_depth | min_sp... | n_esti... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.274822\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:08:29 INFO mlflow.tracking._tracking_service.client: üèÉ View run shivering-stork-605 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/4ea755ff31774e12908d7a122137acd0.\n",
      "2024/09/19 19:08:29 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.7167   \u001b[0m | \u001b[0m0.8238   \u001b[0m | \u001b[0m12.61    \u001b[0m | \u001b[0m0.05283  \u001b[0m | \u001b[0m906.7    \u001b[0m | \u001b[0m73.0     \u001b[0m | \u001b[0m0.7143   \u001b[0m | \u001b[0m0.7173   \u001b[0m | \u001b[0m0.6114   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.276683\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:08:32 INFO mlflow.tracking._tracking_service.client: üèÉ View run unique-gnat-226 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/d7a92e32058b44e094b1a6531c8f8c7b.\n",
      "2024/09/19 19:08:32 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.6844   \u001b[0m | \u001b[0m0.5876   \u001b[0m | \u001b[0m11.85    \u001b[0m | \u001b[0m0.09287  \u001b[0m | \u001b[0m108.9    \u001b[0m | \u001b[0m18.09    \u001b[0m | \u001b[0m0.8502   \u001b[0m | \u001b[0m0.4856   \u001b[0m | \u001b[0m0.9384   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.276076\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:08:36 INFO mlflow.tracking._tracking_service.client: üèÉ View run melodic-carp-670 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/834b7b7983884fccb9b888d7a38377fc.\n",
      "2024/09/19 19:08:36 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.6923   \u001b[0m | \u001b[0m0.6537   \u001b[0m | \u001b[0m10.82    \u001b[0m | \u001b[0m0.05814  \u001b[0m | \u001b[0m202.3    \u001b[0m | \u001b[0m79.11    \u001b[0m | \u001b[0m0.3126   \u001b[0m | \u001b[0m0.646    \u001b[0m | \u001b[0m0.5163   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.276018\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:08:40 INFO mlflow.tracking._tracking_service.client: üèÉ View run fearless-conch-990 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/6d97b14f28b540a28b303494e30a564f.\n",
      "2024/09/19 19:08:40 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.6912   \u001b[0m | \u001b[0m0.5832   \u001b[0m | \u001b[0m11.45    \u001b[0m | \u001b[0m0.02278  \u001b[0m | \u001b[0m969.7    \u001b[0m | \u001b[0m91.44    \u001b[0m | \u001b[0m0.8657   \u001b[0m | \u001b[0m0.03216  \u001b[0m | \u001b[0m0.8997   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.274707\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:08:44 INFO mlflow.tracking._tracking_service.client: üèÉ View run honorable-yak-714 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/07a79f5dbc4b408688c4183128c9bae2.\n",
      "2024/09/19 19:08:44 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.7159   \u001b[0m | \u001b[0m0.9531   \u001b[0m | \u001b[0m15.56    \u001b[0m | \u001b[0m0.02297  \u001b[0m | \u001b[0m470.3    \u001b[0m | \u001b[0m98.08    \u001b[0m | \u001b[0m0.329    \u001b[0m | \u001b[0m0.5955   \u001b[0m | \u001b[0m0.7679   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.274635\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:08:48 INFO mlflow.tracking._tracking_service.client: üèÉ View run respected-boar-694 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/3d57e703c5de4b7e969bc92aa98b5cf7.\n",
      "2024/09/19 19:08:48 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m6        \u001b[0m | \u001b[95m0.7178   \u001b[0m | \u001b[95m0.8016   \u001b[0m | \u001b[95m15.22    \u001b[0m | \u001b[95m0.0949   \u001b[0m | \u001b[95m468.2    \u001b[0m | \u001b[95m96.61    \u001b[0m | \u001b[95m0.1101   \u001b[0m | \u001b[95m0.9599   \u001b[0m | \u001b[95m0.7319   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.180217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.274707\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:08:52 INFO mlflow.tracking._tracking_service.client: üèÉ View run clean-snake-506 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/77a77ba5cec747e384d66d307eac471c.\n",
      "2024/09/19 19:08:52 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.7169   \u001b[0m | \u001b[0m0.8209   \u001b[0m | \u001b[0m13.63    \u001b[0m | \u001b[0m0.001519 \u001b[0m | \u001b[0m439.3    \u001b[0m | \u001b[0m86.88    \u001b[0m | \u001b[0m0.8864   \u001b[0m | \u001b[0m0.4162   \u001b[0m | \u001b[0m0.6807   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.274881\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:08:56 INFO mlflow.tracking._tracking_service.client: üèÉ View run loud-horse-201 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/95a23c52f5834ec1b45bb157b4211fdf.\n",
      "2024/09/19 19:08:56 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.7148   \u001b[0m | \u001b[0m0.7113   \u001b[0m | \u001b[0m9.334    \u001b[0m | \u001b[0m0.0408   \u001b[0m | \u001b[0m466.3    \u001b[0m | \u001b[0m60.66    \u001b[0m | \u001b[0m0.04462  \u001b[0m | \u001b[0m0.5043   \u001b[0m | \u001b[0m0.7964   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.274961\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:09:00 INFO mlflow.tracking._tracking_service.client: üèÉ View run unequaled-skink-162 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/e23b97515d2b446b91c7dcd381b7734d.\n",
      "2024/09/19 19:09:00 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.7137   \u001b[0m | \u001b[0m0.9619   \u001b[0m | \u001b[0m16.32    \u001b[0m | \u001b[0m0.08567  \u001b[0m | \u001b[0m865.1    \u001b[0m | \u001b[0m61.56    \u001b[0m | \u001b[0m0.2863   \u001b[0m | \u001b[0m0.9691   \u001b[0m | \u001b[0m0.6945   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.275393\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:09:04 INFO mlflow.tracking._tracking_service.client: üèÉ View run spiffy-rook-478 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/b49d189132894e4ebd4e51e439642f1b.\n",
      "2024/09/19 19:09:04 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.7059   \u001b[0m | \u001b[0m0.8837   \u001b[0m | \u001b[0m6.675    \u001b[0m | \u001b[0m0.02004  \u001b[0m | \u001b[0m899.8    \u001b[0m | \u001b[0m26.33    \u001b[0m | \u001b[0m0.5089   \u001b[0m | \u001b[0m0.2457   \u001b[0m | \u001b[0m0.8501   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.275395\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:09:08 INFO mlflow.tracking._tracking_service.client: üèÉ View run unique-penguin-340 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/48a646abea3346df8b349eb359a459f4.\n",
      "2024/09/19 19:09:08 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.7089   \u001b[0m | \u001b[0m0.887    \u001b[0m | \u001b[0m5.311    \u001b[0m | \u001b[0m0.007111 \u001b[0m | \u001b[0m885.6    \u001b[0m | \u001b[0m99.68    \u001b[0m | \u001b[0m0.6429   \u001b[0m | \u001b[0m0.4088   \u001b[0m | \u001b[0m0.5021   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.289215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.27831\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:09:12 INFO mlflow.tracking._tracking_service.client: üèÉ View run rare-owl-35 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/311af99e369444d6902ee390735f9b86.\n",
      "2024/09/19 19:09:12 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.6363   \u001b[0m | \u001b[0m0.5135   \u001b[0m | \u001b[0m14.63    \u001b[0m | \u001b[0m0.02852  \u001b[0m | \u001b[0m810.2    \u001b[0m | \u001b[0m61.63    \u001b[0m | \u001b[0m0.2155   \u001b[0m | \u001b[0m0.9324   \u001b[0m | \u001b[0m0.7381   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.278689\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:09:16 INFO mlflow.tracking._tracking_service.client: üèÉ View run silent-grouse-622 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/cb3347662861415ea603131534341351.\n",
      "2024/09/19 19:09:16 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.6237   \u001b[0m | \u001b[0m0.5256   \u001b[0m | \u001b[0m19.95    \u001b[0m | \u001b[0m0.02003  \u001b[0m | \u001b[0m401.5    \u001b[0m | \u001b[0m15.81    \u001b[0m | \u001b[0m0.9745   \u001b[0m | \u001b[0m0.3998   \u001b[0m | \u001b[0m0.5038   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.278922\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:09:19 INFO mlflow.tracking._tracking_service.client: üèÉ View run tasteful-bug-154 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/5216fa11bee94e13879617246f6a739d.\n",
      "2024/09/19 19:09:19 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.6249   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m551.7    \u001b[0m | \u001b[0m29.35    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.275962\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:09:23 INFO mlflow.tracking._tracking_service.client: üèÉ View run colorful-gull-875 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/c3b2f99e88e643f58fa66cd2bf89255d.\n",
      "2024/09/19 19:09:23 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.6931   \u001b[0m | \u001b[0m0.7584   \u001b[0m | \u001b[0m19.48    \u001b[0m | \u001b[0m0.001115 \u001b[0m | \u001b[0m998.2    \u001b[0m | \u001b[0m12.3     \u001b[0m | \u001b[0m0.5706   \u001b[0m | \u001b[0m0.9847   \u001b[0m | \u001b[0m0.7855   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.278922\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:09:27 INFO mlflow.tracking._tracking_service.client: üèÉ View run unleashed-snail-976 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/2c99e4896f2f496f91916618ae98720e.\n",
      "2024/09/19 19:09:27 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.6245   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m291.9    \u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.278922\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:09:31 INFO mlflow.tracking._tracking_service.client: üèÉ View run bemused-stork-445 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/2cad5f8699864415a4fb46f44d77227f.\n",
      "2024/09/19 19:09:31 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.6245   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.276085\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:09:34 INFO mlflow.tracking._tracking_service.client: üèÉ View run able-cow-21 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/488f9743dfa14144a21b507c72b80775.\n",
      "2024/09/19 19:09:34 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.6926   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m198.1    \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's binary_logloss: 0.245727\tvalid_0's custom_cost: 36434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/19 19:09:49 INFO mlflow.tracking._tracking_service.client: üèÉ View run sedate-shrew-568 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/acc0495beb02462085d8b7f7d6756bc7.\n",
      "2024/09/19 19:09:49 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m19       \u001b[0m | \u001b[95m0.7587   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m15.7     \u001b[0m | \u001b[95m0.005677 \u001b[0m | \u001b[95m669.9    \u001b[0m | \u001b[95m100.0    \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.27497\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:09:53 INFO mlflow.tracking._tracking_service.client: üèÉ View run grandiose-auk-513 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/1091f1eaac8f41ac9c997fbb1e1857d4.\n",
      "2024/09/19 19:09:53 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.7137   \u001b[0m | \u001b[0m0.9828   \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m678.7    \u001b[0m | \u001b[0m58.53    \u001b[0m | \u001b[0m0.6726   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.9935   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.278922\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:09:56 INFO mlflow.tracking._tracking_service.client: üèÉ View run kindly-bird-267 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/2d6c9b449e434f72a99dd6c763948d79.\n",
      "2024/09/19 19:09:56 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.6245   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m633.6    \u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's binary_logloss: 0.245853\tvalid_0's custom_cost: 36636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/19 19:10:08 INFO mlflow.tracking._tracking_service.client: üèÉ View run zealous-cub-33 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/b0bd4382daab478694eb92b5ae91ba9d.\n",
      "2024/09/19 19:10:08 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m22       \u001b[0m | \u001b[95m0.7593   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m20.0     \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m692.0    \u001b[0m | \u001b[95m99.96    \u001b[0m | \u001b[95m0.06498  \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m1.0      \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.275402\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:10:11 INFO mlflow.tracking._tracking_service.client: üèÉ View run enthused-ant-331 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/47fb3154fbfc4f51b687008bec5dab3c.\n",
      "2024/09/19 19:10:11 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.7089   \u001b[0m | \u001b[0m0.9393   \u001b[0m | \u001b[0m5.655    \u001b[0m | \u001b[0m0.06252  \u001b[0m | \u001b[0m684.8    \u001b[0m | \u001b[0m82.98    \u001b[0m | \u001b[0m0.5077   \u001b[0m | \u001b[0m0.5914   \u001b[0m | \u001b[0m0.6239   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.179140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.274677\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:10:16 INFO mlflow.tracking._tracking_service.client: üèÉ View run auspicious-pig-424 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/bfc3de74ba524b749dd9f51aeda57727.\n",
      "2024/09/19 19:10:16 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.7172   \u001b[0m | \u001b[0m0.6921   \u001b[0m | \u001b[0m16.95    \u001b[0m | \u001b[0m0.03689  \u001b[0m | \u001b[0m726.6    \u001b[0m | \u001b[0m98.26    \u001b[0m | \u001b[0m0.3986   \u001b[0m | \u001b[0m0.6616   \u001b[0m | \u001b[0m0.9722   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.279354\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:10:19 INFO mlflow.tracking._tracking_service.client: üèÉ View run skillful-crane-759 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/0031fa91d68e4d31865d402e18e125ce.\n",
      "2024/09/19 19:10:19 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.5975   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m694.1    \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.275241\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:10:23 INFO mlflow.tracking._tracking_service.client: üèÉ View run rebellious-steed-644 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/7aa6f9b2e78046db8eb8d823d6fa4261.\n",
      "2024/09/19 19:10:23 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.7107   \u001b[0m | \u001b[0m0.9312   \u001b[0m | \u001b[0m16.73    \u001b[0m | \u001b[0m0.02083  \u001b[0m | \u001b[0m945.9    \u001b[0m | \u001b[0m39.75    \u001b[0m | \u001b[0m0.6323   \u001b[0m | \u001b[0m0.1979   \u001b[0m | \u001b[0m0.5715   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.278921\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:10:27 INFO mlflow.tracking._tracking_service.client: üèÉ View run clean-croc-372 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/acd06fc02c784c2b8abe7691cb916eb6.\n",
      "2024/09/19 19:10:27 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.6245   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m392.6    \u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.6099   \u001b[0m | \u001b[0m0.7121   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.276071\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:10:31 INFO mlflow.tracking._tracking_service.client: üèÉ View run clean-shark-600 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/b19b2b2b386f4e958bbf43a88b1fe48d.\n",
      "2024/09/19 19:10:31 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.6926   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m262.8    \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.275959\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:10:35 INFO mlflow.tracking._tracking_service.client: üèÉ View run clumsy-cat-499 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/8e0de41360c84af99ffe5ef6bdc84cd9.\n",
      "2024/09/19 19:10:35 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.6931   \u001b[0m | \u001b[0m0.7672   \u001b[0m | \u001b[0m16.61    \u001b[0m | \u001b[0m0.07404  \u001b[0m | \u001b[0m861.0    \u001b[0m | \u001b[0m12.83    \u001b[0m | \u001b[0m0.8428   \u001b[0m | \u001b[0m0.6179   \u001b[0m | \u001b[0m0.5994   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.275398\tvalid_0's custom_cost: 37240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\projet7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024/09/19 19:10:39 INFO mlflow.tracking._tracking_service.client: üèÉ View run victorious-hound-936 at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/460d6cefef484c99973a6283b72515ce.\n",
      "2024/09/19 19:10:39 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n",
      "2024/09/19 19:10:39 INFO mlflow.tracking._tracking_service.client: üèÉ View run LightGBM BayesOpt - Hyperparameter Tuning at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/8f34d48226de4c7babfcb7e223d49a27.\n",
      "2024/09/19 19:10:39 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.709    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m1e+03    \u001b[0m | \u001b[0m56.65    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er une liste pour stocker les r√©sultats interm√©diaires\n",
    "intermediate_results = []\n",
    "\n",
    "# Initialiser MLflow\n",
    "mlflow.set_experiment(\"LightGBM-Model-Optimization\")  # Nommer l'exp√©rience\n",
    "\n",
    "# D√©marrer une nouvelle ex√©cution\n",
    "with mlflow.start_run(run_name=\"LightGBM BayesOpt - Hyperparameter Tuning\") as run:\n",
    "\n",
    "    # Fonction d'√©valuation √† optimiser\n",
    "    def lgb_evaluate(n_estimators, num_leaves, colsample_bytree, subsample, max_depth, reg_alpha, reg_lambda, min_split_gain):\n",
    "        # D√©finir le mod√®le avec les hyperparam√®tres √† optimiser\n",
    "        clf = LGBMClassifier(\n",
    "            n_estimators=int(n_estimators),          \n",
    "            num_leaves=int(num_leaves),              \n",
    "            colsample_bytree=max(min(colsample_bytree, 1), 0), \n",
    "            subsample=max(min(subsample, 1), 0),     \n",
    "            max_depth=int(max_depth),                \n",
    "            reg_alpha=max(reg_alpha, 0),            \n",
    "            reg_lambda=max(reg_lambda, 0),           \n",
    "            min_split_gain=min_split_gain           \n",
    "        )\n",
    "\n",
    "        # Entra√Æner le mod√®le sur l'ensemble d'entra√Ænement\n",
    "        clf.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], eval_metric=custom_loss, callbacks=[early_stopping(stopping_rounds=10)])\n",
    "\n",
    "        # Pr√©dire les probabilit√©s sur le jeu de validation\n",
    "        y_proba_val = clf.predict_proba(x_valid)[:, 1]\n",
    "        y_pred = clf.predict(x_valid)\n",
    "\n",
    "        # Calculer les taux de FP et FN\n",
    "        recall = recall_score(y_valid, y_pred)\n",
    "        precision = precision_score(y_valid, y_pred)\n",
    "        f1 = f1_score(y_valid, y_pred)\n",
    "        \n",
    "        # Calculer l'AUC sur le jeu de validation\n",
    "        auc = roc_auc_score(y_valid, y_proba_val)\n",
    "\n",
    "        with mlflow.start_run(nested=True):\n",
    "            # Loguer les m√©triques dans MLflow\n",
    "            mlflow.log_metric(\"AUC\", auc)\n",
    "            mlflow.log_metric(\"Recall\", recall)\n",
    "            mlflow.log_metric(\"Precision\", precision)\n",
    "            mlflow.log_metric(\"F1 Score\", f1)\n",
    "\n",
    "            # Loguer les hyperparam√®tres dans MLflow\n",
    "            mlflow.log_param(\"n_estimators\", int(n_estimators))\n",
    "            mlflow.log_param(\"num_leaves\", int(num_leaves))\n",
    "            mlflow.log_param(\"colsample_bytree\", colsample_bytree)\n",
    "            mlflow.log_param(\"subsample\", subsample)\n",
    "            mlflow.log_param(\"max_depth\", int(max_depth))\n",
    "            mlflow.log_param(\"reg_alpha\", reg_alpha)\n",
    "            mlflow.log_param(\"reg_lambda\", reg_lambda)\n",
    "            mlflow.log_param(\"min_split_gain\", min_split_gain)\n",
    "        \n",
    "        return auc\n",
    "\n",
    "    # D√©finir les limites de recherche pour chaque hyperparam√®tre\n",
    "    param_V1 = {\n",
    "                'n_estimators': (100, 1000),              # Nombre d'estimations entre 100 et 1000\n",
    "                'num_leaves': (10, 100),                  # Nombre de feuilles entre 10 et 100\n",
    "                'colsample_bytree': (0.5, 1),             # Pourcentage d'√©chantillons par arbre\n",
    "                'subsample': (0.5, 1),                    # Pourcentage d'√©chantillons dans chaque arbre\n",
    "                'max_depth': (5, 20),                     # Profondeur maximale de l'arbre\n",
    "                'reg_alpha': (0, 1),                      # R√©gularisation L1\n",
    "                'reg_lambda': (0, 1),                     # R√©gularisation L2\n",
    "                'min_split_gain': (0, 0.1)                # Gain minimal pour diviser un n≈ìud\n",
    "                }\n",
    "\n",
    "    # Instancier l'optimiseur bay√©sien\n",
    "    optimizer = BayesianOptimization(f=lgb_evaluate, pbounds=param_V1, random_state=88)\n",
    "\n",
    "    # Lancer l'optimisation bay√©sienne\n",
    "    optimizer.maximize(init_points=5, n_iter=25)\n",
    "    \n",
    "    # Enregistrer les meilleurs hyperparam√®tres obtenus dans MLflow\n",
    "    best_params = optimizer.max['params']\n",
    "    mlflow.log_params(best_params)\n",
    "    \n",
    "    # Enregistrer la meilleure performance (AUC) obtenue dans MLflow\n",
    "    mlflow.log_metric(\"Best AUC\", optimizer.max['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c9248e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T17:11:26.280419Z",
     "start_time": "2024-09-19T17:11:11.411715Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 21101, number of negative: 240279\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12979\n",
      "[LightGBM] [Info] Number of data points in the train set: 261380, number of used features: 243\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432480\n",
      "[LightGBM] [Info] Start training from score -2.432480\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's binary_logloss: 0.245853\tvalid_0's custom_cost: 36636\n",
      "AUC sur le jeu de validation: 0.7593065254158269\n",
      "Taux de Faux Positifs (FP): 0.001556493644317619\n",
      "Taux de Faux N√©gatifs (FN): 0.9820085929108485\n",
      "Recall (Rappel): 0.01799140708915145\n",
      "Precision (Pr√©cision): 0.5037593984962406\n",
      "Specificity (Sp√©cificit√©): 0.9984435063556824\n",
      "F1 Score: 0.03474202748249935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/19 19:11:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/09/19 19:11:26 INFO mlflow.tracking._tracking_service.client: üèÉ View run LightGBM BayesOpt - Hyperparameter Tuning at: http://127.0.0.1:8080/#/experiments/681732145855945694/runs/90c435f414a944bf82e83c685b56ac45.\n",
      "2024/09/19 19:11:26 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/681732145855945694.\n"
     ]
    }
   ],
   "source": [
    "# Hyperparam√®tres optimis√©s\n",
    "param_V2 = {\n",
    "            'n_estimators': int(optimizer.max['params']['n_estimators']),\n",
    "            'num_leaves': int(optimizer.max['params']['num_leaves']),\n",
    "            'colsample_bytree': optimizer.max['params']['colsample_bytree'],\n",
    "            'subsample': optimizer.max['params']['subsample'],\n",
    "            'max_depth': int(optimizer.max['params']['max_depth']),\n",
    "            'reg_alpha': optimizer.max['params']['reg_alpha'],\n",
    "            'reg_lambda': optimizer.max['params']['reg_lambda'],\n",
    "            'min_split_gain': optimizer.max['params']['min_split_gain']\n",
    "            }\n",
    "\n",
    "# D√©marrer une session MLflow\n",
    "with mlflow.start_run(run_name=\"LightGBM BayesOpt - Hyperparameter Tuning\") as run:    \n",
    "    \n",
    "    # Instanciation du mod√®le avec les hyperparam√®tres optimis√©s\n",
    "    clf_V2 = LGBMClassifier(**param_V2)\n",
    "\n",
    "    # Entra√Æner le mod√®le avec les donn√©es d'entra√Ænement\n",
    "    clf_V2.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], eval_metric=custom_loss, callbacks=[early_stopping(stopping_rounds=10)])\n",
    "\n",
    "    # Pr√©dire sur le jeu de validation et calculer l'AUC\n",
    "    y_proba_val = clf_V2.predict_proba(x_valid)[:, 1]\n",
    "    auc_score = roc_auc_score(y_valid, y_proba_val)\n",
    "\n",
    "    print(f'AUC sur le jeu de validation: {auc_score}')\n",
    "    \n",
    "    # Pr√©dire les classes sur le jeu de validation\n",
    "    y_pred = clf_V2.predict(x_valid)\n",
    "\n",
    "    # Obtenir la matrice de confusion\n",
    "    tn, fp, fn, tp = confusion_matrix(y_valid, y_pred).ravel()\n",
    "\n",
    "    # Calculer les taux de FP et FN\n",
    "    taux_fp = fp / (fp + tn)\n",
    "    taux_fn = fn / (fn + tp)\n",
    "    recall = recall_score(y_valid, y_pred)\n",
    "    precision = precision_score(y_valid, y_pred)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1 = f1_score(y_valid, y_pred)\n",
    "    cm = confusion_matrix(y_valid, y_pred)\n",
    "\n",
    "    print(f\"Taux de Faux Positifs (FP): {taux_fp}\")\n",
    "    print(f\"Taux de Faux N√©gatifs (FN): {taux_fn}\")\n",
    "    print(f\"Recall (Rappel): {recall}\")\n",
    "    print(f\"Precision (Pr√©cision): {precision}\")\n",
    "    print(f\"Specificity (Sp√©cificit√©): {specificity}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    \n",
    "    # Enregistrer la matrice de confusion dans un fichier\n",
    "    np.savetxt(\"confusion_matrix.txt\", cm, fmt='%d')\n",
    "    \n",
    "    # Enregistrer les m√©triques dans MLflow\n",
    "    mlflow.log_metric(\"AUC\", auc_score)\n",
    "    mlflow.log_metric(\"Precision\", precision)\n",
    "    mlflow.log_metric(\"Recall\", recall)\n",
    "    mlflow.log_metric(\"F1 Score\", f1)\n",
    "\n",
    "    # Enregistrer la matrice de confusion comme artefact\n",
    "    mlflow.log_artifact(\"confusion_matrix.txt\")\n",
    "\n",
    "    # Enregistrer les hyperparam√®tres dans MLflow\n",
    "    mlflow.log_param(\"n_estimators\", int(optimizer.max['params']['n_estimators']))\n",
    "    mlflow.log_param(\"num_leaves\", int(optimizer.max['params']['num_leaves']))\n",
    "    mlflow.log_param(\"colsample_bytree\", optimizer.max['params']['colsample_bytree'])\n",
    "    mlflow.log_param(\"subsample\", optimizer.max['params']['subsample'])\n",
    "    mlflow.log_param(\"max_depth\", int(optimizer.max['params']['max_depth']))\n",
    "    mlflow.log_param(\"reg_alpha\", optimizer.max['params']['reg_alpha'])\n",
    "    mlflow.log_param(\"reg_lambda\", optimizer.max['params']['reg_lambda'])\n",
    "    mlflow.log_param(\"min_split_gain\", optimizer.max['params']['min_split_gain'])\n",
    "\n",
    "    # Enregistrer le mod√®le LightGBM dans MLflow\n",
    "    mlflow.lightgbm.log_model(clf_V2, \"lightgbm_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d7aa8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207181f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e89e850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a15dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d1afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e69b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8c73cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab5ba78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c6cd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a968c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a332c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1136aec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af54ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72798cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
