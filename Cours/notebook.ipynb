{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Déploiement d'un modèle de régression à l'aide de MLflow / Ray / Cortex\n",
    "\n",
    "## Déroulé du webinaire\n",
    "Dans cet exercice, nous allons entraîner un modèle de régression afin de prédire le prix médian des maisons de la Californie. Ensuite, nous déploierons ce modèle à travers une API REST en utilisant trois librairies dédiées : MLflow, Ray et Cortex. Ces librairies permettent toutes de déployer des modèles de machine learning, c'est en tout cas une de leurs fonctionnalités ! pourquoi toutes les utiliser alors ? nous allons les comparer !\n",
    "Vous pourrez tester vos prédictions avec une interface Streamlit qui est déjà implémentée pour vous ;)\n",
    "\n",
    "Pour résumer, au programme :\n",
    "1. Récupération des données, recherche des hyperparamètres, construction d'un pipeline.\n",
    "2. Déploiement de l'API REST avec MLflow.\n",
    "3. Interaction du tableau de bord Streamlit avec l'API MLflow.\n",
    "4. Déploiement de l'API REST avec Ray et Cortex.\n",
    "\n",
    "Du côté des librairies utiles pour le projet : scikit-learn, mlflow, ray, cortex, streamlit.\n",
    "\n",
    "### Nota Bene\n",
    "Vous avez peut-être déjà entendu parler de Flask qui est une librairie Python pour construire des APIs, c'est d'ailleurs le [sujet d'un cours](https://openclassrooms.com/fr/courses/4525361-realisez-un-dashboard-avec-vos-donnees/5774811-creez-une-api-avec-flask) sur OpenClassrooms !\n",
    "\n",
    "Dans cet exercice, nous n'utiliserons pas Flask, l'objectif est au contraire de vous faire votre point de vue sur des outils différents, plus spécifiques, conçus uniquement pour répondre aux problématiques propres au machine learning.\n",
    "\n",
    "\n",
    "## Introduction au déploiement d'un modèle\n",
    "Une fois le travail de modélisation terminé, il est temps de mettre votre travail à disposition de vos utilisateurs.\n",
    "\n",
    "Nous allons pour cela créer une API REST qui donnera accès à votre modèle, voici le déroulé de son utilisation en pratique :\n",
    "1. **Envoi par l'utilisateur** d'une requête (contenant les données d'entrée du modèle) au service web en charge de la prédiction.\n",
    "2. **Réception par le service** de la requête, le modèle pré-traite et prédit un résultat.\n",
    "3. **Envoi par le service** de la prédiction en réponse à la requête utilisateur originale.\n",
    "4. **Réception par l'utilisateur** de la prédiction et affichage à l'écran.\n",
    "\n",
    "Si les termes que nous avons utilisé ne vous semblent pas clairs, c'est le moment de vous former sur ce sujet important qu'est l'utilisation d'une API REST :\n",
    "- https://openclassrooms.com/fr/courses/4525361-realisez-un-dashboard-avec-vos-donnees/5774786-apprehendez-le-fonctionnement-dun-serveur-web\n",
    "- https://openclassrooms.com/fr/courses/6573181-adoptez-les-api-rest-pour-vos-projets-web\n",
    "- https://practicalprogramming.fr/api-rest/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Entraînez un modèle de régression (45 minutes)\n",
    "### Présentation du jeu de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données California Housing synthétise la situation immobilière de la Californie par quartier à l'aide de 8 variables :\n",
    "- `MedInc` revenu médian dans le secteur (en 10K $)\n",
    "- `HouseAge` âge médian des maisons dans le secteur\n",
    "- `AveRooms` nombre moyen de pièces\n",
    "- `AveBedrms` nombre moyen de chambres\n",
    "- `Population` taille de la population dans le secteur\n",
    "- `AveOccup` occupation moyenne de la maison\n",
    "- `Latitude` latitude du secteur\n",
    "- `Longitude` longitude du secteur\n",
    "\n",
    "Avec ces variables prédictives, l'objectif est d'estimer le prix médian des maisons pour un secteur donné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, preprocessing, model_selection, ensemble, pipeline\n",
    "from sklearn.experimental import enable_hist_gradient_boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Téléchargement du jeu de données\n",
    "<img src='./images/logo_oc.png' width=15px /> [Suivre le lien](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html#sklearn.datasets.fetch_california_housing) pour télécharger les données. Extrayez uniquement du jeu de données :\n",
    "- Les variables prédictives dans la matrice `X`.\n",
    "- La variable cible dans le vecteur `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/logo_oc.png' width=15px /> Vérifiez la taille de la matrice `X` et du vecteur `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20640, 8), (20640,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de mesurer les performances de notre modèle sur des données de test, nous allons séparer les données en deux bases : apprentissage et test.\n",
    "\n",
    "[Cours pour bien comprendre comment évaluer un modèle](https://openclassrooms.com/fr/courses/4297211-evaluez-les-performances-dun-modele-de-machine-learning)\n",
    "\n",
    "<img src='./images/logo_oc.png' width=15px /> Séparez les deux variables (`X` et `y`) en deux bases, retenez 80% des données pour l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/logo_oc.png' width=15px /> Vérifiez la taille des matrices `X_train` et `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16512, 8), (4128, 8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant centrer et réduire nos variables prédictives, c'est la [standardisation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Attention à la fuite de données, la base de test doit être normalisée avec les paramètres appris sur la base d'apprentissage. \n",
    "\n",
    "<img src='./images/logo_oc.png' width=15px /> Effectuez la standardisation des variables `X_train` et `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche des hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour modéliser la relation qu'il existe entre les variables prédictives `X_train` et la cible `y_train`, nous allons utiliser un modèle ensembliste basé sur le boosting : [HistGradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor).\n",
    "\n",
    "**Le choix du modèle n'est pas très important pour cet exercice**, si jamais vous avez un blocage, utilisez un modèle de régression linéaire ou un arbre de décision.\n",
    "\n",
    "Pour le modèle `HistGradientBoostingRegressor` nous allons rechercher les hyperparamètres les plus adaptés afin d'obtenir les meilleures performances, utilisez pour cela la classe `GridSearchCV`. Les hyper-paramètres importants sont : `learning_rate`, `max_depth`, `min_samples_leaf`, `max_iter`. Référez vous à la documentation pour bien les comprendre !\n",
    "\n",
    "**Indices** :\n",
    "- learning_rate entre 1e-1 et 3e-1\n",
    "- max_depth entre 2 et 5\n",
    "- min_samples_leaf entre 30 et 32\n",
    "- max_iter entre 100 et 150\n",
    "\n",
    "<img src='./images/logo_oc.png' width=15px /> Effectuez la recherche des hyperparamètres par validation-croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=HistGradientBoostingRegressor(),\n",
       "             param_grid={'learning_rate': [0.1, 0.2, 0.3],\n",
       "                         'max_depth': [2, 4, 5], 'max_iter': [100, 150],\n",
       "                         'min_samples_leaf': [30, 31, 32]})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = ensemble.HistGradientBoostingRegressor()\n",
    "params = {'learning_rate': [1e-1, 2e-1, 3e-1],\n",
    "          'max_depth': [2, 4, 5],\n",
    "          'min_samples_leaf': [30, 31, 32],\n",
    "          'max_iter': [100, 150]\n",
    "          }\n",
    "gsv = model_selection.GridSearchCV(regressor, params, cv=5)\n",
    "gsv.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/logo_oc.png' width=15px /> Affichez le meilleur score obtenu ainsi que les meilleurs hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8362064442371151,\n",
       " {'learning_rate': 0.2,\n",
       "  'max_depth': 5,\n",
       "  'max_iter': 150,\n",
       "  'min_samples_leaf': 32})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsv.best_score_, gsv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/logo_oc.png' width=15px /> Affichez le coefficient de détermination moyen sur la base de test (faites un scoring de la base de test). *Pas de problème si votre score est moins bon ! ce n'est pas l'objectif de l'exercice.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8294976590349341"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsv.best_estimator_.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) de prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous souhaitons maintenant réunir toutes les étapes nécessaires à la prédiction dans des conditions réelles, pour cela nous devons regrouper la standardisation et la régression dans un seul outil, c'est le rôle d'un pipeline.\n",
    "\n",
    "<img src='./images/logo_oc.png' width=15px /> Construisez un [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) de prédiction intégrant l'étape de [pré-traitement](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) et la [régression](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html). N'oubliez pas d'utiliser les hyperparamètres que vous avez trouvé à l'étape précédente pour configurer votre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline.Pipeline([('scaler', preprocessing.StandardScaler()), \n",
    "                              ('regressor', ensemble.HistGradientBoostingRegressor(**gsv.best_params_))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/logo_oc.png' width=15px /> Lancez l'apprentissage du pipeline sur les données d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('regressor',\n",
       "                 HistGradientBoostingRegressor(learning_rate=0.2, max_depth=5,\n",
       "                                               max_iter=150,\n",
       "                                               min_samples_leaf=32))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/logo_oc.png' width=15px /> Calculez les performances (coefficient de détermination) sur la base de test, le résultat devrait être proche du précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8311388338846891"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le pipeline regroupe maintenant toutes les étapes nécessaires pour prédire sur des données, nous allons maintenant le déployer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/logo_oc.png' width=15px /> Sérialiser le pipeline à l'aide de [joblib](https://scikit-learn.org/stable/modules/model_persistence.html), sous le nom de fichier `pipeline_housing.joblib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline_housing.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline, 'pipeline_housing.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour la suite des exercices\n",
    "\n",
    "À partir de maintenant, **il est vivement conseillé d'utiliser le terminal** de votre système d'exploitation pour installer les librairies et pour lancer les déploiements le moment venu. \n",
    "\n",
    "En effet, un notebook jupyter n'est pas un environnement adapté pour ce type de travail, qui est à la frontière de l'administration système et du développement, c'est le [MLOps](https://www.google.com/search?q=mlops) !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Déploiement d'un modèle sklearn avec MLflow (40 minutes)\n",
    "\n",
    "### Installation avec Pip\n",
    "\n",
    "<img src='./images/logo_oc.png' width=15px /> Exécutez la commande suivante dans le terminal associé à votre environnement Python `pip install mlflow`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Présentation de MLflow\n",
    "\n",
    "> MLflow is a platform to streamline machine learning development, including tracking experiments, packaging code into reproducible runs, and sharing and **deploying models**. MLflow offers a set of lightweight APIs that can be used with any existing machine learning application or library (TensorFlow, PyTorch, XGBoost, etc), wherever you currently run ML code (e.g. in notebooks, standalone applications or the cloud). MLflow's current components are:\n",
    ">- MLflow Tracking: An API to log parameters, code, and results in machine learning experiments and compare them using an interactive UI.\n",
    ">- MLflow Projects: A code packaging format for reproducible runs using Conda and Docker, so you can share your ML code with others.\n",
    ">- **MLflow Models: A model packaging format and tools that let you easily deploy the same model (from any ML library) to batch and real-time scoring on platforms >such as Docker, Apache Spark, Azure ML and AWS SageMaker.**\n",
    ">- MLflow Model Registry: A centralized model store, set of APIs, and UI, to collaboratively manage the full lifecycle of MLflow Models.\n",
    "\n",
    "[Source](https://github.com/mlflow/mlflow)\n",
    "\n",
    "--------\n",
    "\n",
    "MLflow est une librairie dédiée à la gestion du cycle de vie d'un projet de machine learning, à savoir :\n",
    "- le suivi des résultats liés aux expériences (MLflow Tracking)\n",
    "- garantir la reproducibilité des expériences et le partage de code (MLflow Projects)\n",
    "- la gestion des modèles sous un format normalisé afin de simplifier les déploiements locaux ou cloud (MLflow Models)\n",
    "- la centralisation et le versionnage les modèles (MLflow Model Registry)\n",
    "\n",
    "**On s'intéresse dans le cadre de l'exercice à MLflow Models uniquement**, vous pouvez explorer les autres fonctionnalités bien entendu, cependant ce n'est pas l'objectif de cet exercice.\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format de stockage d'un modèle\n",
    "\n",
    "Un modèle MLflow est un répertoire contenant une liste de fichiers, dont un nommé MLmodel qui liste les différentes flavors (terme MLflow) dans lesquelles le modèle est utilisable.\n",
    "\n",
    "Les flavors sont une façon pratique de définir comment exécuter un modèle, cette convention facilite le déploiement car la flavor standardise la façon de prédire à partir d'un modèle. MLflow définit par exemple des flavors pour une fonction python, sklearn, tensorflow, xgboost.\n",
    "\n",
    "Dans le répertoire de sauvegarde du modèle MLflow, le fichier MLmodel contient l'ensemble des flavors disponibles, par exemple :\n",
    "```yaml\n",
    "time_created: 2018-05-25T17:28:53.35\n",
    "\n",
    "flavors:\n",
    "  sklearn:\n",
    "    sklearn_version: 0.19.1\n",
    "    pickled_model: model.pkl\n",
    "  python_function:\n",
    "    loader_module: mlflow.sklearn\n",
    "```\n",
    "\n",
    "Tous les outils supportant les flavors `python_function` ou `sklearn` pourront utiliser ce modèle, par exemple pour un déploiement avec la commande suivante.\n",
    "\n",
    "```python\n",
    "mlflow models serve -m my_model\n",
    "```\n",
    "\n",
    "D'autres outils cloud comme AWS SageMaker ou Azure ML peuvent utiliser ces flavors.\n",
    "\n",
    "[Documentation pour approfondir](https://mlflow.org/docs/latest/models.html#storage-format)\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signature d'un modèle\n",
    "\n",
    "Afin de garantir que les données d'entrée d'un modèle sont conformes à ce qui est attendu, les modèles MLflow peuvent inclure des metadatas décrivant les entrées et sorties :\n",
    "- Model Signature - description des entrées et sorties du modèle\n",
    "- Model Input Example - exemple d'une entrée valide\n",
    "\n",
    "La signature du modèle permet de renseigner le nom des colonnes et leurs types afin de vérifier si ils sont similaires lors de la prédiction.\n",
    "\n",
    "[Documentation](https://mlflow.org/docs/latest/models.html#model-signature-and-input-example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/logo_oc.png' width=15px />  Utiliser la fonction `infer_signature` afin d'extraire la signature à partir des données d'entrée et de sortie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = infer_signature(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### Sauvegarde du modèle sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/logo_oc.png' width=15px />  Sauvegarder le pipeline à l'aide de la fonction [save_model](https://mlflow.org/docs/latest/python_api/mlflow.sklearn.html#mlflow.sklearn.save_model) en n'oubliant pas de préciser la signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.save_model(pipeline, 'mlflow_model', signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/logo_oc.png' width=15px />  Vérifier qu'un répertoire correspondant au modèle vient bien d'être généré. Ce dernier doit contenir trois fichiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Déploiement d'une API REST\n",
    "\n",
    "Les commandes suivantes sont à lancer **depuis le terminal** associé à votre environnement Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/logo_oc.png' width=15px />  À partir du modèle MLflow, vous n'êtes plus qu'à une commande de lancer un serveur pour votre API REST ([documentation](https://mlflow.org/docs/latest/models.html#deploy-mlflow-models)). À vous de jouer ! [(en cas de blocage)](https://mlflow.org/docs/latest/cli.html#mlflow-models-serve)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mlflow models serve -m mlflow_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/logo_oc.png' width=15px />  Écrivez la requête curl pour envoyer une requête. Faites attention aux guillemets :)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "curl http://127.0.0.1:5000/invocations -H 'Content-Type: application/json' -d '{\"data\": [[1, 2, 3, 4, 5, 6, 7, 8]]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si votre requête ne fonctionne pas, **ne bloquez pas**, vous pourrez tout de même tester votre API avec le dashboard qui est déjà configuré pour envoyer une requête."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion et perspectives de MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'utilisation de MLflow pour le déploiement offre des options intéressantes, nous avons vu comment mettre en place une API REST, nous aurions également pu générer une image Docker pour la déployer sur un service cloud comme [Azure ML](https://docs.microsoft.com/fr-fr/azure/databricks/_static/notebooks/mlflow/mlflow-quick-start-deployment-azure.html). De plus la fonctionnalité MLflow Models n'est qu'une des quatre grandes qui forment MLflow, le potentiel n'est donc pas complètement exploré."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ressources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Documentation MLflow](https://www.mlflow.org/docs/latest/index.html)\n",
    "- [Déploiement avec Azure ML](https://docs.microsoft.com/fr-fr/azure/databricks/_static/notebooks/mlflow/mlflow-end-to-end-example-azure.html)\n",
    "- [Documentation MLflow Microsoft](https://docs.microsoft.com/fr-fr/azure/databricks/applications/mlflow/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3 - Configuration du tableau de bord Streamlit (10 minutes)\n",
    "\n",
    "Nous allons maintenant connecter un tableau de bord qui nous a été fourni par une autre équipe, à notre API MLflow. Le tableau de bord est implémenté avec la librairie [Streamlit](https://www.streamlit.io/), elle est très simple d'utilisation, en quelques minutes on peut mettre en place des champs de saisie et des affichages, le tout en Python.\n",
    "\n",
    "<img src='./images/logo_oc.png' width=15px />  Regardez dans le dossier racine, il contient le fichier `dashboard.py` qui contient le descriptif de l'interface et une fonction permettant d'envoyer une requête.\n",
    "\n",
    "<img src='./images/logo_oc.png' width=15px />  Affectez l'adresse du serveur de l'API à la variable `MLFLOW_URI` dans la fonction `main`.\n",
    "\n",
    "<img src='./images/logo_oc.png' width=15px />  Installez Streamlit si ce n'est pas déjà fait :\n",
    "\n",
    "`pip install streamlit`\n",
    "\n",
    "<img src='./images/logo_oc.png' width=15px />  Avec la console, depuis le répertoire racine, lancer Streamlit avec la commande suivante :\n",
    "\n",
    "`streamlit run dashboard.py`\n",
    "\n",
    "Vous devriez voir apparaitre un nouvel onglet dans votre navigateur, c'est le tableau de bord qui s'affiche !\n",
    "\n",
    "<img src='./images/streamlit.png' width=500px />\n",
    "\n",
    "<img src='./images/logo_oc.png' width=15px />  Lancez une prédiction en appuyant sur le bouton en bas de page, si vous avez bien configuré le serveur de l'API et que l'adresse est correcte, un résultat sera affiché."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion générale\n",
    "\n",
    "À travers ce tutorial, vous avez comparé trois outils qui proposent au moins une fonctionnalité de déploiement d'API orientée pour le machine learning :\n",
    "- MLflow pour déployer en local ou sur les clouds (AWS, Azure) et qui dispose d'autres fonctionnalités comme le suivi d'expérience, la création d'un registre de modèles.\n",
    "- Ray Tune pour déployer en local ou sur un cluster que vous gérez, propose la création rapide d'un backend (modèle ou logique métier) et d'un point d'accès associé. Vous pourrez gérer la montée en puissance des vos services directement depuis la console Python.\n",
    "- Cortex pour déployer en local ou sur AWS (bientôt GCP). Cortex se focalise exclusivement sur le déploiement et le cycle de vie du modèle, avec de nombreuses options pour paramétrer l'infrastructure.\n",
    "\n",
    "À vous d'utiliser la librairie qui semble la plus adaptée à votre projet / entreprise / cloud !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
